# DDS 训练异常的根因说明

## 问题现象
- 训练 50 epoch 后，loss 下降但 `val_mAP@0.5` 和 `meanIoU` 近乎为 0，预测框在图 1/2/3 呈现“乱标注”。

## 直接原因（标注被静默丢弃）
- DDS 标注文件中实际存在 **6 个类别 id（0–5）**。例如 `Augmented_Data/train/labels/100_jpg.rf.0de758cbda471ed8e47e8c336796094c.txt` 的第一行就是类别 `5` 的框。
- 但旧版 `config.py` 将 `NUM_CLASSES` 设为 3，并在 `parse_yolo_annotation` 中对 `cls_idx >= NUM_CLASSES` 的框直接 `continue`，导致 **id ≥3 的框全部被跳过**。
- 这样一来，数据集中大部分目标在训练/验证时都不存在：
  - 训练损失仍能下降（模型只在少量“合法”框上收敛），
  - 但验证计算 mAP/IoU 时几乎找不到匹配框，于是指标接近 0，视觉上也表现为乱框。

## 现有修复
- 将默认类别数改为 6，并提供与 id 对应的占位名称，避免默认配置再次截断标签。【F:config.py†L47-L58】
- 解析标注时改为 **显式报错**（而不是静默跳过）当遇到超出 `NUM_CLASSES` 的 id，第一时间暴露配置-数据不匹配问题。【F:datasets/dental_dds.py†L20-L34】
- 在 README 中提示 DDS 默认含 6 类，使用前应确认并同步配置，避免误配。【F:README.md†L31-L35】

## 建议排查/使用方式
1. 如果你替换了自定义数据或精简了类别，务必同步修改 `NUM_CLASSES` 和 `CLASS_NAMES`，并确认标注文件里的最大 id 没有超出范围。
2. 运行一个快速 sanity check（例如读取几份标签并统计最大类 id），确认不会触发解析时的越界报错。
3. 若仍有 mAP 异常，继续检查 anchors、输入尺寸、以及评估时的置信度阈值，但首先确保“标签未被丢弃”这一根因已解决。

## v2 debug
- **现象复盘**：在类别数修正后，val mAP 依然约为 0、mean IoU ≈ 0.005，验证可视化中红框（预测）与绿框（GT）严重错位。
- **红框/绿框含义**：评估可视化里，绿色框是标注真值，红色框是模型预测结果（含置信度和类别文字）。
- **新发现的根因**：评估阶段在 `Evaluator.compute` 中错误地把**已为 xyxy 的预测框再次按 cxcywh 解读并转换**，导致 IoU 计算几乎为 0，所有匹配被判为负样本，从而 mAP/IoU 继续塌陷。【F:utils/metrics.py†L39-L84】【F:utils/metrics.py†L72-L78】
- **修复办法**：移除对预测框的错误二次转换，仅对 GT 做 cxcywh→xyxy，再用同一坐标系计算 IoU；验证重跑后指标才会反映模型真实水平。【F:utils/metrics.py†L72-L78】

## v3 debug
- **最新现象**：修复坐标系后，50 epoch 训练输出 `val_mAP@0.5≈0.20`、`meanIoU≈0.005`，可视化里红框数量远多于绿框且大多不重合。
- **问题定位**：验证阶段的置信度阈值仍设为 `0.05`，会把大量极低置信度的候选框也纳入 NMS 与评估；这些弱候选既拉低 mAP 精度，也在 mean IoU 计算中被计入，导致平均 IoU 被“海量低质量框”稀释到接近 0，视觉上表现为满屏红框。
- **处理措施**：
  - 将验证阈值提高到与推理一致的 `0.25`，过滤掉大部分无意义的低置信度框，减少红框噪声。【F:config.py†L63-L68】
  - 在解码阶段加入按分数排序的 `MAX_DETECTIONS` 限制（50），即便模型产出过多候选也只保留高分框，避免指标与可视化被低质量框主导。【F:models/yolotiny.py†L51-L67】
- **后续建议**：使用新的阈值和截断策略重新验证/可视化；如需更激进过滤，可进一步提高阈值或调小 `MAX_DETECTIONS`，但首要目标是屏蔽低置信度噪声以观测模型真实定位质量。

## v4 debug
- **最新现象**：更高阈值后，`val_mAP@0.5≈0.16`、`meanIoU≈0.024`，红框依然明显多于绿框且重合度不足，表明模型仍在产出大量与 GT 不匹配的候选。
- **问题根因**：
  - 主干网络最终特征图下采样 1/32，配合只有一组方形 anchor（32/64/128），对 DDS 中**细长且高度主导的牙齿框（宽度四分位数 ~37–56px，高度四分位数 ~105–150px，长宽比中位 2.8）**分辨率过粗且形状不匹配。网格粒度过大 → 中心/尺寸回归量化误差大，方形 anchor 难以覆盖纵向目标，导致预测框大量偏移/变形，与 GT 几乎不重合，mAP 和 IoU 双双受损，视觉上表现为“满屏红框但命中少”。
- **修复措施**：
  - 将网络最终 stride 从 32 收敛到 **16**，把输出特征图从 20×20 提升到 40×40，显著细化定位粒度，减少因网格过粗造成的中心偏移。【F:config.py†L36-L38】【F:models/backbone.py†L17-L28】
  - 将 anchor 更新为**纵向长条形** `(40×110, 56×140, 72×180)` 以贴合真实框的尺寸分布，降低回归偏差。【F:config.py†L26-L33】
  - 进一步收紧验证/推理置信度阈值到 0.35 并将解码最大保留框数降至 30，避免长尾低分框继续充斥评估和可视化，使指标更聚焦于高质量候选。【F:config.py†L64-L67】
- **后续验证建议**：用上述配置重新训练或从现有权重继续 fine-tune；关注 IoU 是否提升（粒度和 anchor 适配应优先改善定位），若仍有漏检可再微调阈值或增加多尺度/额外检测层，但先用 stride16 + 长条 anchor 验证改动效果。

## v5 debug
- **现象复盘**：
  - 第 9 epoch 出现 `meanIoU≈0.64` 但 `mAP≈0.00` 的异常组合，表面上似乎“框和 GT 重合度很高”，但分类几乎全错。
  - 训练到 50 epoch 后仍停留在 `mAP≈0.04` / `IoU≈0.12`，可视化里红框数量依旧明显多于绿框且重叠有限，说明分类与抑制仍未稳定。
- **原因排查**：
  1. **类别极度不平衡 → 框定位对但类别错**：训练集中类别分布极斜（class5=3293、class0=853、class3=69）。未加权的 BCE 会让主频类主导分类头，导致模型把多类牙齿都判为高频类。出现“框位置对但类别错”时 IoU 按位置算会很高，但 mAP 按类别算会接近 0，对应中途的异常指标。【F:datasets/dental_dds.py†L14-L31】【F:train.py†L41-L52】
  2. **跨类别 NMS 导致“错抑制 + 冗余”**：解码阶段用全局 NMS，跨类别的重叠框会互相抑制，残留的次高分框又以另一类别输出，既引入大量红框，也进一步拉低分类精度。【F:models/yolotiny.py†L46-L90】
  3. **初始偏置过高，早期就产生海量低质框**：`pred` 卷积的 objectness/class 偏置默认为 0，训练早期会输出大量 0.5 左右的置信度，负样本损失占据主导，难以收敛到稳态，红框数量长期偏多。【F:models/head.py†L16-L28】
- **修复与改进（已实施）**：
  - **加入类别加权 BCE**：按训练标签频次动态计算 class weight，并在分类损失中归一化使用，提升长尾类梯度占比，降低“框对但类错”带来的低 mAP。【F:datasets/dental_dds.py†L14-L31】【F:losses/detection_loss.py†L11-L33】【F:train.py†L41-L52】
  - **改为每类独立 NMS + 全局 Top-K**：先按类别做 NMS 再整体按分数截断，避免跨类错抑制并减少重复红框，让评估/可视化更接近真实分类结果。【F:models/yolotiny.py†L46-L90】
  - **下调预测头偏置**：在检测头初始化时将 objectness 与类别偏置设为 -4，抑制训练初期的低质高分框，配合阈值/Top-K 策略降低红框噪声。【F:models/head.py†L16-L28】
- **对“中途高 IoU 低 mAP”现象的判断**：
  - 该现象源于分类失衡导致的伪好转：定位可对齐 GT，所以 IoU 能短暂飙高；但分类几乎全错，mAP/召回趋近 0，因此不可视为真实提升。
  - 观察验证曲线时应同时看 PR / confusion matrix，而非单看 IoU，避免被“框对类错”的假信号误导训练决策。
- **后续优化建议**：
  1. 用当前改动重新训练或接着 fine-tune，关注 mAP 是否随分类稳定而回升；若 GPU 允许可延长训练到 150 epoch 让加权分类头充分收敛。
  2. 若仍有大量红框，可适度提高 `CONF_THRESHOLD`（如 0.45）或进一步调低 `MAX_DETECTIONS`，在可视化/验证时增强过滤，同时观察长尾类的召回不要过度下降。
 3. 若想进一步提升长尾表现，可在当前权重基础上加入 focal loss 或增设额外检测层；但建议先用“加权 BCE + 类内 NMS”重新评估，确认主要分类/抑制问题已收敛后再做更大改动。

## v6 debug
- **最新现象**：50 epoch 后 `mAP@0.5≈0.05`、`meanIoU≈0.15`，可视化中红框数量仍多且与 GT 重叠度普遍偏低，提示评估阶段仍存在系统性偏差。
- **新定位的根因**：训练/验证时对长条全景片直接拉伸到 `640×640`，但 GT 框依然使用**原图坐标的归一化数值**。模型预测在拉伸后坐标系下计算，评估却用未拉伸的 GT → 预测与 GT 落在不同坐标系，IoU 被系统性压低，表现为“红框多、指标低”。
- **修复措施**：
  - 为 DDS 引入 letterbox 预处理：按最长边等比例缩放后四周填充到正方形，保持纵横比不变，并用同样的缩放/填充值同步变换 GT 框，统一坐标系。【F:datasets/dental_dds.py†L18-L26】【F:datasets/dental_dds.py†L125-L168】
  - 移除强制拉伸的 `Resize`，保持图像几何不被扭曲，使 anchor/stride 与实际牙齿形态匹配，减少不必要的回归偏差。【F:datasets/dental_dds.py†L52-L59】
- **改进预期**：对齐预测与 GT 坐标系后，IoU 计算将反映真实定位质量，mAP 不再被“坐标错位”拖垮；结合此前的类内 NMS 和长条 anchor，红框数量应显著收敛，指标回归到模型真实水平。

## v7 debug
- **最新现象**：引入 letterbox 后，输出图像尺寸改变（左右/上下留灰边），但预测红框仍大面积偏离绿色 GT 框，mAP/IoU 仍低。
- **定位出的剩余问题**：
  - 推理/评估阶段的框坐标仍停留在**填充后的 640×640 坐标系**，在对比/绘制到原始全景片时没有撤销填充与缩放，导致红框在原图上偏移（尤其在长条形图像的左右灰边区域），评价指标也在错误坐标系下计算。
- **修复措施**：
  1. 数据集返回 letterbox 的缩放比例与四边填充值，并保留原图尺寸及原始 GT，方便统一反变换。【F:datasets/dental_dds.py†L70-L116】
  2. 新增 `unletterbox_boxes`，在评估和可视化前将预测框从 640×640 填充坐标系映射回原图绝对坐标；GT 也回到原图像素空间后再计算 IoU/mAP，避免坐标系错位带来的假低分。【F:datasets/dental_dds.py†L118-L137】【F:utils/metrics.py†L11-L63】
  3. `eval.py`/`infer_visualize.py` 改为在原图上绘制绿框/红框，确保肉眼对齐效果与指标一致，不再受灰边干扰。【F:eval.py†L41-L63】【F:infer_visualize.py†L44-L74】
- **后续建议**：
  - 用修复后的坐标系重新跑验证/可视化，确认红框与绿框重合度的真实情况。如果 mAP/IoU 仍低，则表明模型表达能力或训练轮次仍不足，可在坐标系正确的前提下再考虑多尺度训练、翻转等数据增强或延长训练轮次。

## v8 debug
- **最新现象**：坐标系修复后，指标仍徘徊在 `mAP@0.5≈0.12`、`meanIoU≈0.03`，可视化里依旧出现大量与 GT 不重叠的红框。
- **新增根因**：数据标注存在**非法框（超界或宽高为 0）**，在训练/评估时被当作有效目标加入损失与匹配，导致回归损失被错误监督拉偏、NMS 里混入畸形候选，从而输出更多高偏移的红框，拖低 mAP/IoU。
- **修复措施**：
  - 为标注解析新增严格校验：中心/宽高必须在 (0,1] 且类别 id 合法，否则将该框丢弃并打印 warning，防止坏标签进入训练/评估。【F:datasets/dental_dds.py†L20-L69】
- **下一步验证**：
  1. 用 v8 过滤后重新训练或在最新权重上继续 fine-tune，观察红框数量是否减少、mAP/IoU 是否抬升；日志中若出现 warning，需回溯对应图片并在标注层面修正。
  2. 若仍有异常，可在数据层面统计并人工检查被丢弃的文件，确认是否存在系统性标注偏移或成批错误标注。

## v9 debug
- **暴露的新问题**：命令行评估入口 `eval.py` 缺少 `argparse` 与 `Path` 的导入，直接运行会在解析参数前抛出 `NameError`，导致最新版的评估/可视化压根无法跑通，前面几轮的“验证”实际上没有真正覆盖最新模型与修复。
- **影响**：无法生成新的 mAP/IoU 与红/绿框对比图，容易误以为代码层面仍有模型质量问题，实则评估链路中断。
- **修复措施**：补全必要的标准库导入，确保 `python eval.py --checkpoint ...` 能正常运行并产出最新指标与可视化。【F:eval.py†L1-L19】

## v10 debug
- **澄清**：本轮修复只恢复了评估/可视化链路，不会直接改善训练过程的 mAP/IoU。训练质量要靠重新跑一遍验证或可视化对比（`eval.py` / `infer_visualize.py`），确认模型在最新代码下的真实表现。
- **建议**：先用修复后的 `eval.py` 跑一次验证，拿到可比的 mAP/IoU 与红/绿框对齐图，再决定是否需要进一步改动模型或数据。

## v11 debug
- **残留问题**：`build_yolo_target` 对同一网格单元只保留“最后写入”的目标，若两颗牙中心落在同一 cell（DDS 全景片常见），后写的框会覆盖前一个，导致大量 GT 在训练中被静默丢弃 → 模型召回难以提升，mAP/IoU 长期偏低。
- **修复措施**：为每个 cell 跟踪已占用的 anchor，按框-Anchor IoU 从高到低选择“首个空闲 anchor”，避免无声覆盖；若 cell 已被 3 个 anchor 占满才回退到最高 IoU anchor。中心落在边界时还会 clamp 到合法网格索引，防止越界。【F:datasets/dental_dds.py†L158-L202】
- **预期影响**：同一网格内的多颗牙都能生成监督信号，减少正样本丢失，提升召回与分类的可学习性；再次训练/验证时 mAP 与 IoU 应随更完整的监督而回升。

## v12 debug
- **最新现象**：即便修复了目标覆盖、坐标系等问题，验证阶段 `val_mAP@0.5≈0.10`、`val_meanIoU≈0.04` 仍然偏低，且日志显示验证几乎没有高置信度预测被统计。
- **根因定位**：验证/可视化解码使用的 `conf_threshold=0.35` 过高，而训练早期的 objectness 与分类 logits 仍然偏保守，大量中等置信度框在进入 NMS 前被阈值滤掉，导致召回显著低估、指标被“卡死”。
- **修复措施**：将验证阶段的置信度阈值降到 0.05，以便保留更多候选供 NMS 与匹配计算，真实反映模型召回水平；同时补上 `infer_visualize.py` 漏掉的 `argparse` 导入，保证可视化脚本能正常运行。【F:config.py†L46-L48】【F:infer_visualize.py†L1-L20】
- **预期影响**：更低的验证阈值会显著提升召回，mAP/IoU 将不再因“入口过滤过严”而虚低，可据此判断模型是否仍需进一步优化；可视化脚本恢复可用，便于肉眼检查框对齐情况。

## v13 debug
- **最新现象**：在使用极低验证阈值 (`conf_threshold=0.05`) 时，验证输出仍然充斥大量置信度极低且与 GT 无重合的红框，`val_meanIoU` 被拖到 ~0.005 级别，mAP 也被低质量候选稀释。
- **定位出的偏差**：
  1. 评价 IoU 时直接对**所有预测框**求最大 IoU 再平均，即便这些框与任何 GT 都不匹配也计入分母，导致海量低质框把均值压到接近 0。
  2. 过低的验证阈值持续放行极弱候选，进一步放大了上述 IoU 稀释效应，也让 mAP 被低精度框占比压低。
- **修复措施**：
  - 调高验证解码阈值到 0.20，在不明显牺牲召回的前提下过滤掉最弱的候选，避免评估被“红框噪声”主导。【F:config.py†L46-L50】
  - 在评估均值 IoU 时改为按置信度排序做贪心匹配，只统计 IoU≥阈值且尚未匹配过的 GT，对应预测才纳入均值，反映模型实际命中质量而非被无匹配框稀释。【F:utils/metrics.py†L37-L80】
- **预期效果**：验证阶段将聚焦于有意义的候选，均值 IoU 不再被大量无匹配框“冲零”，mAP 也能反映真正的精准/召回水平；若指标仍低，则可据此判断模型本身是否仍需继续训练或改进。

## v14 debug
- **最新现象**：即使修正阈值/匹配逻辑，训练仍出现“召回极低、mAP/IoU 长期卡死”的症状，日志里 objectness 迅速压到极低，推理/验证几乎无高分框。
- **根因定位**：损失函数把**所有非正样本的 anchor 都当作强负样本**，没有忽略与 GT 重叠度高的邻近 anchor。全景片里同一牙齿往往跨越多个 anchor/cell，被标记为负样本的邻近 anchor 会在反向传播中被强烈惩罚，导致模型学会“不要预测”，召回被系统性抑制，输出框极少且质量差。
- **修复措施**：
  - 在计算 objectness 损失前，为每张图计算所有预测框与 GT 的 IoU，**当最大 IoU 超过 `OBJ_IGNORE_IOU` (0.5) 时，将该 anchor 标记为 ignore**，既不当正样本也不计入负样本惩罚，只对真正远离 GT 的区域施加负梯度。【F:losses/detection_loss.py†L39-L71】
  - 在配置中新增 `OBJ_IGNORE_IOU`，便于后续根据数据密度调节忽略阈值。【F:config.py†L63-L68】
- **预期效果**：邻近 GT 的 anchor 不再被当作强负样本，模型可以安全地在目标周围探索多组候选，召回与 mAP/IoU 应随训练轮次显著回升；可视化脚本恢复可用后，可直接观察红框数量与对齐情况验证修复成效。

## v15 debug
- **新增需求**：多轮改动后仍无法锁定训练质量低的根因，需要在训练过程中落地**可追溯的调试快照**，便于事后定位是标签缺失、正样本过少，还是模型输出被压制。
- **新增调试输出**：
  - `logs/dataset_stats.json` 每次训练启动时写出标签目录、有效框/非法框数量、各类频次以及每图框数分布，第一时间暴露标签异常或极度不平衡。【F:datasets/dental_dds.py†L42-L75】【F:train.py†L43-L50】【F:train.py†L90-L100】
  - 每个 epoch 结束写出 `logs/debug_epoch_xxx.json`，记录该轮的训练/验证损失、每图正样本数量均值、当前指标、首个验证 batch 的原图尺寸、GT/预测数量、平均 objectness，以及低阈值候选与 GT 的互相 IoU 均值，帮助判断是监督缺失、模型不出框，还是匹配/阈值问题。【F:train.py†L56-L130】
- **使用方法**：训练完成后逐个检查 `logs/debug_epoch_*.json`，结合 `dataset_stats.json` 判断：
  - 若 `train_pos_per_image` 持续 <1，说明标签在网格里找不到落点（需检查 anchor/尺度或标签是否合法）。
  - 若 `num_pred_low_thresh` 远大于 GT 但 IoU 均值极低，说明模型在乱发框（需关注阈值/NMS/损失权重）。
  - 若 objectness 均值被压到极低且候选几乎为 0，则需继续调整忽略阈值或学习率，避免负样本过强。

## v16 debug
- **数据分布暴露的核心瓶颈**：DDS 的类别极端不平衡，且在验证/测试集中长尾类样本接近于无：
  - 训练集中 class5=3293，但 class1 仅 172、class3 仅 69；验证集中 class5=67，而 class1 只有 4、class3 只有 3；测试集中 class5=54，class1 仅 5，class3 完全缺失。长尾类几乎没有验证/测试样本，导致它们的 AP 轻易被压到 0，即便定位 IoU 较高，整体 mAP 仍被主频类主导并拉低。【F:REPORT.md†L143-L150】
  - 你反馈的评估结果（IoU≈0.72 但 mAP≈0.125，class0/1/4 AP=0）与这一分布吻合：模型主要在 class2/5 上有命中，长尾类因样本稀缺、置信度偏低而被 NMS/阈值过滤，几乎没有正确检测被统计，mAP 因长尾类全 0 被平均后显著偏低。
- **新增调试与佐证手段**：
  - `dataset_stats.json` 现按 train/valid/test 全量写出每类计数与非法框数量，训练前即可确认长尾样本量与数据健康度，而不必只盯住训练集。【F:train.py†L90-L102】
  - 评估器新增 `per_class_counts`，在 `debug_epoch_*.json` 里能看到每类 GT、预测、TP/FP、最终召回/精度，直接验证是否存在“只预测高频类、长尾类召回=0”的现象，避免仅凭整体 mAP 难以定位问题。【F:utils/metrics.py†L26-L121】
- **针对当前现象的建议行动**：
  1. 在最新训练输出的 `logs/debug_epoch_*.json` 中查看 `per_class_counts`，确认哪些类的召回/TP 为 0；若长尾类一直无预测，可进一步调低对应类别阈值、提高长尾类 loss 权重或对其做过采样。
  2. 在 `dataset_stats.json` 里确认验证/测试是否存在缺失类（如 class3 在测试集为 0）；对于完全缺失的类，mAP 计算会把它们的 AP 计为 0，可考虑补充标注或在评估时仅针对有样本的类别做对比。
  3. 若标注可疑（非法框或格式问题），利用统计中的 `invalid_boxes` 以及文件名定位数据问题，先修正标签再重训，以免少量坏标签进一步干扰本就稀少的长尾样本。

## v17 debug（最新评估与可视化分析）
- **最新评估回报**：测试集 `mAP@0.5≈0.12`，但 `mean IoU≈0.72`；逐类 AP 仅 class2≈0.44、class5≈0.21，其余类全部为 0。这与 v16 揭示的分布一致：测试集中 class3 完全缺失，class1 仅 5 个样本，class0/4 也极少，导致即便模型有定位（IoU 高），在这些类上几乎没有 TP 被统计，AP 被压成 0，整体 mAP 被长尾类平均后显著偏低。【F:REPORT.md†L143-L150】
- **可视化症状**：用户上传的推理结果仍以 class5/2（红框）为主，绿框标注的长尾类要么缺失要么数量极少；部分红框位置与 GT 有重叠但类别错或置信度低，被评估过滤掉，进一步削弱长尾类的 TP。视觉上表现为“框位置还行但标签错/漏”，与 IoU 高而 mAP 低一致。
- **结论：主要是数据与分布问题，不是单纯模型 bug**：
  - 长尾类（class0/1/3/4）在验证/测试中样本接近于无 → AP 被定义为 0；模型再好也难在 mAP 上抬分，除非补充这些类的 GT 或在评估时排除空缺类。
  - 类别极端不平衡使分类头偏向高频类（class5/2），即便定位成功也会预测为主频类，mAP 因类别错而低；可通过更强的 class weight / focal loss、过采样长尾类、或单独为长尾类放宽置信度阈值缓解。
  - IoU 能到 0.7 说明定位/坐标链路已基本打通；当前瓶颈集中在**长尾类别召回与分类可靠性**，而非框回归或评估阈值。
- **下一步建议**：
  1. 在 `logs/dataset_stats.json` 确认最新数据是否仍缺少 class3/1 等 GT；如测试/验证缺失，补标或在评估时排除空缺类，否则 AP 固定为 0。【F:train.py†L90-L102】
  2. 针对 class0/1/3/4 调高类别权重或引入 focal loss gamma>1，配合少量过采样或 mixup 以增加长尾梯度占比；对这些类单独降低推理/评估阈值，避免被全局阈值滤掉。【F:losses/detection_loss.py†L11-L33】
  3. 若条件允许，延长训练（>150 epoch）并开启 warmup + 多尺度，结合 per-class NMS 继续观察 `debug_epoch_*.json` 中的 per_class_counts 是否出现长尾类 TP；否则 mAP 将继续被长尾类 0 分主导。

## v18 debug（高 IoU 但可视化错位的排查思路）
- **为什么可视化“红框对不上绿框”，但 IoU 仍然高？**
  - `mean_iou` 只在**找到匹配**的预测-标注对上计算均值；当模型只在少数牙齿上产生高置信度框时，这些匹配 IoU 可以很高，但未匹配的 GT 被完全忽略，这就出现“图上大多数绿框没有红框覆盖，但统计均值依然不低”。【F:utils/metrics.py†L19-L89】
  - 部分红框实际回归在正确位置，但**类别预测错**（比如把 class0 牙齿判成 class5），IoU 高但被当作 FP，AP 计 0；可视化上看到框位置合理，却因为类别错/阈值过滤而不计入 mAP，形成“看起来对、指标低”的错觉。【F:models/yolotiny.py†L21-L69】
- **新增调试手段：逐图匹配日志**
  - 评估器支持将每张图的 GT、反 letterbox 后的预测框、匹配关系（预测索引→匹配的 GT、对应 IoU、是否被接受）写入 `debug_eval/eval_matches.jsonl`。借助该日志可以验证：
    1) 是否存在大量 GT 没有任何匹配（召回不足）；
    2) 预测框与哪个 GT 最近、IoU 多高但因类别错/重复而被拒绝；
    3) 是否有阈值过高/NMS 误杀的情况。【F:utils/metrics.py†L19-L121】【F:eval.py†L16-L60】
  - 运行方式：`python eval.py --checkpoint <ckpt> --split test --save-vis inference_outputs --debug-dir debug_eval`；完成后打开 `debug_eval/eval_matches.jsonl` 对照可视化 PNG 检查每张图的匹配详情。
- **排查指引**
  1. 若日志显示大部分 GT 完全无匹配，说明模型召回仍不足（需降低阈值或继续训练）；
  2. 若多数预测匹配到 GT 但 `accepted=false` 且 `iou>=0.5`，多半是类别错或被重复占用，需加强分类分支/调整类权重；
  3. 若匹配 IoU 普遍高且 accepted=true，但 `gt` 中长尾类极少或缺失，说明数据分布仍是主要瓶颈，mAP 难以再升，需要补充标注或对长尾类单独评估。

## v19 debug（新增“数据 vs 模型”可溯源日志）
- **新增数据健康度统计**：`dataset_stats.json` 现在额外记录每类在多少张图中出现、无标注图片数量，便于判断验证/测试是否缺失某些类别，定位“样本稀缺”是否是 mAP 偏低的根因。【F:datasets/dental_dds.py†L43-L77】
- **显式暴露类别缺失与极端不平衡**：统计中增加 `missing_classes`、`class_presence_ratio` 与 `class_imbalance_ratio`，开局即可看到哪些类在当前划分完全缺席，以及频次跨度是否过大，避免把“长尾无样本”误判为模型能力不足。【F:datasets/dental_dds.py†L85-L102】
- **训练/验证损失拆解**：每轮 `debug_epoch_xxx.json` 会落盘 GIoU/Objectness/Class 三个分支的均值损失，结合正样本数可判断是回归/分类倒下还是监督缺失导致模型不出框。【F:train.py†L34-L73】【F:train.py†L104-L135】
- **预测置信度分布**：验证阶段汇总所有解码框的均值/中位数/90 分位置信度，写入调试日志，帮助判断“模型能力不足”（整体置信度低）还是“阈值过高导致被截断”。【F:train.py†L58-L88】【F:train.py†L104-L135】
- **如何使用**：训练完查看最新 `logs/debug_epoch_*.json`，若 `val_confidence` 与 `per_class_counts` 皆显示模型几乎不给长尾类高分框，而 `dataset_stats.json` 又表明这些类在验证集中本就极少甚至缺失，则优先补充标注或重新划分；若数据覆盖正常但置信度普遍低，则需加强模型容量/训练策略（更长训练、focal loss、类权重等）。

