# DDS 训练异常的根因说明

## 问题现象
- 训练 50 epoch 后，loss 下降但 `val_mAP@0.5` 和 `meanIoU` 近乎为 0，预测框在图 1/2/3 呈现“乱标注”。

## 直接原因（标注被静默丢弃）
- DDS 标注文件中实际存在 **6 个类别 id（0–5）**。例如 `Augmented_Data/train/labels/100_jpg.rf.0de758cbda471ed8e47e8c336796094c.txt` 的第一行就是类别 `5` 的框。
- 但旧版 `config.py` 将 `NUM_CLASSES` 设为 3，并在 `parse_yolo_annotation` 中对 `cls_idx >= NUM_CLASSES` 的框直接 `continue`，导致 **id ≥3 的框全部被跳过**。
- 这样一来，数据集中大部分目标在训练/验证时都不存在：
  - 训练损失仍能下降（模型只在少量“合法”框上收敛），
  - 但验证计算 mAP/IoU 时几乎找不到匹配框，于是指标接近 0，视觉上也表现为乱框。

## 现有修复
- 将默认类别数改为 6，并提供与 id 对应的占位名称，避免默认配置再次截断标签。【F:config.py†L47-L58】
- 解析标注时改为 **显式报错**（而不是静默跳过）当遇到超出 `NUM_CLASSES` 的 id，第一时间暴露配置-数据不匹配问题。【F:datasets/dental_dds.py†L20-L34】
- 在 README 中提示 DDS 默认含 6 类，使用前应确认并同步配置，避免误配。【F:README.md†L31-L35】

## 建议排查/使用方式
1. 如果你替换了自定义数据或精简了类别，务必同步修改 `NUM_CLASSES` 和 `CLASS_NAMES`，并确认标注文件里的最大 id 没有超出范围。
2. 运行一个快速 sanity check（例如读取几份标签并统计最大类 id），确认不会触发解析时的越界报错。
3. 若仍有 mAP 异常，继续检查 anchors、输入尺寸、以及评估时的置信度阈值，但首先确保“标签未被丢弃”这一根因已解决。

## v2 debug
- **现象复盘**：在类别数修正后，val mAP 依然约为 0、mean IoU ≈ 0.005，验证可视化中红框（预测）与绿框（GT）严重错位。
- **红框/绿框含义**：评估可视化里，绿色框是标注真值，红色框是模型预测结果（含置信度和类别文字）。
- **新发现的根因**：评估阶段在 `Evaluator.compute` 中错误地把**已为 xyxy 的预测框再次按 cxcywh 解读并转换**，导致 IoU 计算几乎为 0，所有匹配被判为负样本，从而 mAP/IoU 继续塌陷。【F:utils/metrics.py†L39-L84】【F:utils/metrics.py†L72-L78】
- **修复办法**：移除对预测框的错误二次转换，仅对 GT 做 cxcywh→xyxy，再用同一坐标系计算 IoU；验证重跑后指标才会反映模型真实水平。【F:utils/metrics.py†L72-L78】

## v3 debug
- **最新现象**：修复坐标系后，50 epoch 训练输出 `val_mAP@0.5≈0.20`、`meanIoU≈0.005`，可视化里红框数量远多于绿框且大多不重合。
- **问题定位**：验证阶段的置信度阈值仍设为 `0.05`，会把大量极低置信度的候选框也纳入 NMS 与评估；这些弱候选既拉低 mAP 精度，也在 mean IoU 计算中被计入，导致平均 IoU 被“海量低质量框”稀释到接近 0，视觉上表现为满屏红框。
- **处理措施**：
  - 将验证阈值提高到与推理一致的 `0.25`，过滤掉大部分无意义的低置信度框，减少红框噪声。【F:config.py†L63-L68】
  - 在解码阶段加入按分数排序的 `MAX_DETECTIONS` 限制（50），即便模型产出过多候选也只保留高分框，避免指标与可视化被低质量框主导。【F:models/yolotiny.py†L51-L67】
- **后续建议**：使用新的阈值和截断策略重新验证/可视化；如需更激进过滤，可进一步提高阈值或调小 `MAX_DETECTIONS`，但首要目标是屏蔽低置信度噪声以观测模型真实定位质量。

## v4 debug
- **最新现象**：更高阈值后，`val_mAP@0.5≈0.16`、`meanIoU≈0.024`，红框依然明显多于绿框且重合度不足，表明模型仍在产出大量与 GT 不匹配的候选。
- **问题根因**：
  - 主干网络最终特征图下采样 1/32，配合只有一组方形 anchor（32/64/128），对 DDS 中**细长且高度主导的牙齿框（宽度四分位数 ~37–56px，高度四分位数 ~105–150px，长宽比中位 2.8）**分辨率过粗且形状不匹配。网格粒度过大 → 中心/尺寸回归量化误差大，方形 anchor 难以覆盖纵向目标，导致预测框大量偏移/变形，与 GT 几乎不重合，mAP 和 IoU 双双受损，视觉上表现为“满屏红框但命中少”。
- **修复措施**：
  - 将网络最终 stride 从 32 收敛到 **16**，把输出特征图从 20×20 提升到 40×40，显著细化定位粒度，减少因网格过粗造成的中心偏移。【F:config.py†L36-L38】【F:models/backbone.py†L17-L28】
  - 将 anchor 更新为**纵向长条形** `(40×110, 56×140, 72×180)` 以贴合真实框的尺寸分布，降低回归偏差。【F:config.py†L26-L33】
  - 进一步收紧验证/推理置信度阈值到 0.35 并将解码最大保留框数降至 30，避免长尾低分框继续充斥评估和可视化，使指标更聚焦于高质量候选。【F:config.py†L64-L67】
- **后续验证建议**：用上述配置重新训练或从现有权重继续 fine-tune；关注 IoU 是否提升（粒度和 anchor 适配应优先改善定位），若仍有漏检可再微调阈值或增加多尺度/额外检测层，但先用 stride16 + 长条 anchor 验证改动效果。

## v5 debug
- **现象复盘**：
  - 第 9 epoch 出现 `meanIoU≈0.64` 但 `mAP≈0.00` 的异常组合，表面上似乎“框和 GT 重合度很高”，但分类几乎全错。
  - 训练到 50 epoch 后仍停留在 `mAP≈0.04` / `IoU≈0.12`，可视化里红框数量依旧明显多于绿框且重叠有限，说明分类与抑制仍未稳定。
- **原因排查**：
  1. **类别极度不平衡 → 框定位对但类别错**：训练集中类别分布极斜（class5=3293、class0=853、class3=69）。未加权的 BCE 会让主频类主导分类头，导致模型把多类牙齿都判为高频类。出现“框位置对但类别错”时 IoU 按位置算会很高，但 mAP 按类别算会接近 0，对应中途的异常指标。【F:datasets/dental_dds.py†L14-L31】【F:train.py†L41-L52】
  2. **跨类别 NMS 导致“错抑制 + 冗余”**：解码阶段用全局 NMS，跨类别的重叠框会互相抑制，残留的次高分框又以另一类别输出，既引入大量红框，也进一步拉低分类精度。【F:models/yolotiny.py†L46-L90】
  3. **初始偏置过高，早期就产生海量低质框**：`pred` 卷积的 objectness/class 偏置默认为 0，训练早期会输出大量 0.5 左右的置信度，负样本损失占据主导，难以收敛到稳态，红框数量长期偏多。【F:models/head.py†L16-L28】
- **修复与改进（已实施）**：
  - **加入类别加权 BCE**：按训练标签频次动态计算 class weight，并在分类损失中归一化使用，提升长尾类梯度占比，降低“框对但类错”带来的低 mAP。【F:datasets/dental_dds.py†L14-L31】【F:losses/detection_loss.py†L11-L33】【F:train.py†L41-L52】
  - **改为每类独立 NMS + 全局 Top-K**：先按类别做 NMS 再整体按分数截断，避免跨类错抑制并减少重复红框，让评估/可视化更接近真实分类结果。【F:models/yolotiny.py†L46-L90】
  - **下调预测头偏置**：在检测头初始化时将 objectness 与类别偏置设为 -4，抑制训练初期的低质高分框，配合阈值/Top-K 策略降低红框噪声。【F:models/head.py†L16-L28】
- **对“中途高 IoU 低 mAP”现象的判断**：
  - 该现象源于分类失衡导致的伪好转：定位可对齐 GT，所以 IoU 能短暂飙高；但分类几乎全错，mAP/召回趋近 0，因此不可视为真实提升。
  - 观察验证曲线时应同时看 PR / confusion matrix，而非单看 IoU，避免被“框对类错”的假信号误导训练决策。
- **后续优化建议**：
  1. 用当前改动重新训练或接着 fine-tune，关注 mAP 是否随分类稳定而回升；若 GPU 允许可延长训练到 150 epoch 让加权分类头充分收敛。
  2. 若仍有大量红框，可适度提高 `CONF_THRESHOLD`（如 0.45）或进一步调低 `MAX_DETECTIONS`，在可视化/验证时增强过滤，同时观察长尾类的召回不要过度下降。
  3. 若想进一步提升长尾表现，可在当前权重基础上加入 focal loss 或增设额外检测层；但建议先用“加权 BCE + 类内 NMS”重新评估，确认主要分类/抑制问题已收敛后再做更大改动。
